[{"content":" r { color: Red } bl { color: Blue } g { color: Green }  As a final-year student who has some experience about artificial intelligence(AI) and machine learning (ML), it\u0026rsquo;s great for me to have a chance to revisit the definition of AI through the introductory course to AI at Stanford University - CS221 - which content is available online. This is also a chance for me to look back at the Introduction to AI course that I studied in my second year at Hanoi University of Science and Technology (HUST).\nWhat is AI/ML for me, before this course? After many days of reading online content about the definition of AI in my early years at the university, I finally came up and satisfied with a definition of AI that seem to be general enough. In my own expression: \u0026ldquo;Artificial Intelligence is any kind of simulation that exhibit a feature of intelligence\u0026rdquo;. This definition, to me, is acceptable for a number of reasons:\n Some definitions equalize intelligence to human intelligence, which I believe is a limit to themselves. Animals exhibit some kinds of intelligence, and there can be types of intelligence that human don\u0026rsquo;t have. Simulations are created by human in general, but the \u0026ldquo;simulation\u0026rdquo; here is meant to be equivalent to \u0026ldquo;artificial\u0026rdquo; - not occuring in the nature. There are many type of intelligence and abilities associate with intelligence - as from Wikipedia, abstraction, logic, understanding, learning, emotional knowledge, etc. - and there is also no single definition for intelligence. So exhibition of one those traits is acceptable.  The definition of machine learning by Tom M. Mitchell in his book Machine Learning is commonly accepted by everyone:\n \u0026ldquo;A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\u0026rdquo;\n ML is often regarded as a subset of AI. The difference here is, ML has an element called \u0026ldquo;learning\u0026rdquo; - improvement of performance with more data/experience\nMy unanswered questions You might ask \u0026ldquo;So what is the problem for you definition?\u0026rdquo;. Actually, I know that I can have a good definition for my own. The next step is what make me interested in: \u0026ldquo;How to categorize AI/ML in such a way that aligns well with some aspects of natural intelligence?\u0026rdquo;. In fact, there are already some common ways of categorizing AI or ML:\n Grouping by learning methods: supervised learning, unsupervised learning, reinforcement learning,\u0026hellip; Grouping by type of tasks: computer vision, natural language processing, speech processing,\u0026hellip;  While these groupings are useful, I\u0026rsquo;m still not contented, since they are unnatural:\n The groupings just \u0026ldquo;split\u0026rdquo; problems in AI/ML into group according to human-defined concepts (e.g: supervised) or functionalities of human (e.g: see - computer vision, or speak - speech processing) - which ignores general aspects of intelligence (e.g: logic, abstraction) mentioned above There is not much thing to compare between groups. There isn\u0026rsquo;t seem to exist a scale from \u0026ldquo;low\u0026rdquo; to \u0026ldquo;high\u0026rdquo; to measure any aspect of each category in comparison with other categories  Introduction to AI course at my university, and my doubt These are topics that were mentioned in my AI class:\n Searching problems: tree methods (BFS, DFS), heuristic methods, constraint satisfaction problem (CSP) Logic: Propositional logic, First-order logic Machine learning: Some common methods (kNN, naive bayes, decision tree, neural network)  Studying this course made me feel that there wass some kind of ordered categorization here. Maybe the difficulty of the problems is the scale that I\u0026rsquo;m looking for? Or, the scale is based on how abstract the problems are?\nAt the beginnning of the course, there was an introduction and overview of AI history. However, we students were not told why the course was structured in that way - we only knew the topics.\nWhat I learned and deduced from Stanford\u0026rsquo;s AI course First, from the view of this course\u0026rsquo;s lecturer, there are 3 pillars to AI: Modeling (create a mathematical/logical representation of the real world), Inference (answer questions about models, e.g: shortest path, winning strategy), and Learning (transform an abstract model into a concrete one, with the help from additional data).\nThe below image pretty much sums up the categorization of AI/ML problem/model types used in this course. They are sorted by the \u0026ldquo;low-high\u0026rdquo; level of intelligence:\n Reflex-based model is a fixed sequence of computations to get the output. This is equivalent to daily reflexive task that we can do very quickly, such as recognizing an object in the house State-based model considers available states and actions at each state, as well as plan the step-by-step actions that will followed. This is the model of some of our favorite games such as chess and go, or some riddles for children like the prisoners\u0026rsquo; dilemma Variable-based model deals with assignment of variable with respect to some factors/conditions, regardless of order. Sudoku is a game that can be well-modelled in this category. Logic-based model can digest heterogeneous information into some syntax and semantic representations, and reason deeply using inference rules. The common logical analysis we often do in daily life can be represented by this type of model.   \nSo there is an ordered categorization here!!!. A great news for me. However, to make the ordering clearer, I read through the course and try to make some scales to organize the problems/models according to the 3 pillars mentioned above. Here is my own summary of analysis, based on what I learned from the course:\n   Pillar Reflex States Variables Logic Conclusion     Modeling abstract model, \u0026ldquo;massive lookup table of best actions\u0026rdquo; local interactions between states (like in graph) solutions are assigned to variables (lots of possibilities) syntax and semantics, highly expressive Models get simpler and more expressive. Moving from abstract → concrete (less learning)   Inference follow a fixed sequence of steps to get the output combine local interactions to get optimization solutions find assignments to variables, or probabilistic inference draw (deep) logical reasoning from knowledge, but rules can be deterministic Inference gets more complex, and handles less uncertainty   Learning have to learn from (lots of) data get data through exploration action need few data, incorporate prior domain knowledge rule-based, don\u0026rsquo;t allow fine-tuning through data Learning gets easier - but lower ability to fine-tune through additional data    Conclusion In the end, I have found what I need: an ordered grouping that \u0026ldquo;aligns well with some aspects of natural intelligence\u0026rdquo;. This categorization also fill in the hole of my understanding about how my university\u0026rsquo;s Introduction to AI course was structured.\nNeedless to say, there are many topics covered in this course. I think this is a very good course for anyone who want to get an overview of what AI is, and it can also be a starting point to find out more on specific topics of AI/ML.\nReference  Background image: https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/Artificial-Intelligence.jpg/1024px-Artificial-Intelligence.jpg CS221 - Spring 2022 lecture slides (and image references): https://stanford-cs221.github.io/spring2022/modules/ Intelligence - Wikipedia: https://en.wikipedia.org/wiki/Intelligence  ","date":"2022-05-25T20:13:33+07:00","image":"https://dungminhdao.github.io/p/quick-note-on-the-definition-of-ai/Artificial-Intelligence_hu9c1502da57918bcda1993849b624d87b_409576_120x120_fill_q75_box_smart1.jpg","permalink":"https://dungminhdao.github.io/p/quick-note-on-the-definition-of-ai/","title":"Quick note on the definition of AI"},{"content":"","date":"2022-05-19T10:01:59+07:00","image":"https://dungminhdao.github.io/p/chien-tranh-chechnya/background_hu69e68f617e5d8f83eda2d4f1451bbc89_206458_120x120_fill_box_smart1_3.png","permalink":"https://dungminhdao.github.io/p/chien-tranh-chechnya/","title":"Chiến tranh Chechnya"},{"content":"Hi. This is the first course review I\u0026rsquo;ve ever done on my blog, and today I will review the 2 series of courses on the same topic: Machine Learning Operations, or MLOps for short.\nWhat to expect in this review:\n An overview of what these programs do and don\u0026rsquo;t provide The topics that are focused in each series and technological stacks used Methods of teaching, reviewing, and testing My experience studying each of these programs: what I find interesting (and what need to be improved)  What NOT to expect in my review:\n Details on each of the topics (though I do provide some insights) How to complete each projects and tests  Why should you care about MLOps? For most of beginners in Machine Learning or AI, it is a common practice to use notebooks and simple files to do experiments with readily available datasets, run and fine-tune a number of models. While this could be a good starting point for developing practical models, things are quite different in the production scenarios.\nI will not list all of the cumbersome theoretical and practical issues here, as the readers can easily search for posts on the topic of MLOps, as well as find some insights on the problems that MLOps solves through the rest of my course review. However, here is a simple summary of some of the problems that MLOps can provide solutions:\n The real-world data are constantly changing, which needs investigation to take action ML models need to be easy to run, fine-tune, and track to ensure good performances The ML project code should be organized in a pipeline with tracked dependencies for reproducibility and fault tolerance When put into production, model performance should be constantly monitored and retraining should be trigger when there is a significant performance downgrade Model fairness, information securities,\u0026hellip; are also problems for MLOps to deal with   ML system in production \nFigure 1: This is how production ML system looks like You can see that in the end of the day, ML engineers have to work with many other stakeholders - software engineers, data engineers, DevOps, customers, and managers - to implement a successful MLOps project.\nA quick summary of courses and their providers This topic is pretty new, and there are multiple approaches to deal with it. I have experience studying 2 series of courses on the topic of MLOps. The providers of these 2 courses have great reputation in organizing online courses in the topic of Machine Learning. Although these 2 programs are designed for a 3 to 4 months period of studying, it is personally beneficial for me to study each of these program in 1 month (as I can fully focus on MLOps topics). Links for these programs can be found at the reference part. Let\u0026rsquo;s have an overview:\n Coursera Machine Learning Engineering for Production (MLOps) Specialization: Well, another specialization provided by DeepLearning.AI; and from the past experience with their famous ML courses, I had a great expectation that this would be an another wonderful journey. Coursera\u0026rsquo;s courses can be audited for free, or you can get a financial aid to study these courses at a reasonable price - and sometimes for free! Udacity Nanodegree in Machine Learning DevOps Engineer: the first Nanodegree program I have ever taken, and I study this course as a part of training in my company. For the regular students, you can take the courses with the price of as low (or high?) as $120. The price goes with benefit, of course: in return, you will get personalized assessment and suggestion for your project submissions  Coursera MLOps Specialization This is a series of 4 courses, the first course is an introduction, and each of the other 3 courses focus on a specific topic: Data Lifecycle, Modeling Pipelines, and Deploying in Production. TensorFlow Extended (TFX) platform is used for for creating production ML pipelines; the pipelines\u0026rsquo; components are introduced throughout the last 3 courses. Besides, other libraries (ml_metdata, sklearn) and technological platform related to Tensorflow (such as Google Cloud Platform) are also frequently used. A basic familiarity with the Tensorflow library can help you in some scenarios.\n TensorFlow Extended (TFX) \nFigure 2: TensorFlow Extended Pipeline for production ML In every course, there is a series of videos introducing new concepts. After a few videos, small quizzes are provided to test how well you understand these concepts, and there are also hand-on labs for practical experiences. Each course final score is determined by a combination of some specific quizzes and hand-on labs score.\nBenefit of taking this program This specialization introduce a lot of recent concept in Machine Learning and AI such as Semi-supervised learning, Neural Architecture Search (NAS), and Knowledge Distillation. I also find interesting recent techniques in handling data (feature transformation, feature selection) and working with models (quantization and pruning).\nUsing a common platform (TFX) for creating pipeline make the courses in this specialization well-connected and coherent. A wide range of tools revolves around Tensorflow, especially from Google Cloud Platform, also help me to explore the new tools to train and deploy models automatically.\nSide notes: There are some guides provided by Qwiklabs that help learners gain familiarity with deploying ML models on Google Cloud Platform in this courses. I recommend checking out other courses from Qwiklabs for basic understanding of the whole platform. Signing up for a Qwiklabs account through Google and get into the first guide, you will receive 30-days of studying any courses for free. Check out the link: https://www.qwiklabs.com/\n \nFigure 3: Vertex AI on GCP for end-to-end ML workflow (Course 4) Drawback, or things that this program needs to improve Unfortunately, this program requires basic knowledge in Deep Learning (e.g. completion of the Deep Learning Specialization) for comprehension of the recent concepts mentioned above, so it\u0026rsquo;s quite difficult for learners with knowledge in just traditional Machine Learning algorithms to understand many parts in these courses.\nSince the topic of the specialization is about MLOps, too much advanced or in-depth discussion on a specific state-of-the-art Machine Learning techniques can distract the learners from the main purpose.\nThe hand-on labs provided are great in the knowledge provided; however, there aren\u0026rsquo;t much room for creativity and most of the time, learners just have to follow the instruction provided in the description in the notebooks or the guidelines in external labs to complete the graded exercises. This has 2 main disadvantages:\n It is difficult to remember the knowledge provided if you just follow the instructions and not doing something for yourself. The course can be quite tedious sometimes. There are no project to complete for your own goods. Personally, I think that pushing projects you have done in the course to GitHub can help showing your ability and skill to recruiters a lot.  Udacity ML DevOps Nanodegree This Nanodegree is also divided into 4 courses.\n The first course helps developing skills that are necessary for production models, includes clean code, version control, testing and logging. The second course focuses on building a organized and reproducible end-to-end machine learning pipeline from scratch using MLFlow. Besides, experiments, codes and results are tracked using Github and Wandb (Weights and Biases) The third course teaches students about model deployment. Data Version Control (DVC) is used for data and models, and CI/CD workflow is built with Github Actions and Heroku. The final course is about automating all the stuffs mentioned above with DevOps process, including diagnose operational issues, as well as retraining and redeployment of models  Videos are used for introducing new concepts to the learners in each course. After each concepts, there are questions and programming exercises (not counted toward the final course accomplishment) for students to reinforce their knowledge on the topic. Finally, after completing all the lessons, there is a final project for each course, which students have to complete and satisfy all the requirements in the rubric to get pass the project.\n \nFigure 4: Experiments and model tracking using Wandb (second project, my implementation) Benefit of taking this program First of all, this Nanodegree doesn\u0026rsquo;t require you to have knowledge in Deep Learning; in fact, all the model used in the courses are simple traditional Machine Learning models. This is a great way to introduce MLOps concepts without going too much into other sophisticated methods specific to handling data or models.\nThere are also multiple technologies introduced in this program. However, compared to the Coursera\u0026rsquo;s technological stacks, the tools in this course are easier to learn and apply in practice. The deployment part using CI/CD is one of the most challenging but rewarding part that I have learned in doing the projects.\nI find this Nanodegree\u0026rsquo;s projects very exciting to complete. There are many requirements in the rubrics, but it still create many rooms for my own creativity and improvements. Since not everything is provided readily like in the Coursera MLOps\u0026rsquo; hand-on labs, I have the experience of implementing from scratch for some parts of the project, which strengthen my ability to use the tools and reinforce my understanding of the concepts and the whole system.\nLast but not least, the personalized assessment and suggestion for project submissions gives me lots of insight on how to improve my implementation and best practices in MLOps.\n \nFigure 5: ML system that allows scheduled re-train, re-deploy, monitor, and report on the model (final project) Drawback, or things that this program needs to improve Compared to the DeepLearningAI\u0026rsquo;s specialization, this Nanodegree doesn\u0026rsquo;t have implementation of MLOps for Deep Learning models. This is a drawback, since the MLOps process benefit the most for that type of model - which require frequent training, fine-tuning, and deployment compared to traditional one.\nThere are trade-off in introducing a number of different libraries and focusing on a specific tools. From my point of view, the concepts are presented in an organized manner, but it can still be a challenge for other learners to keep track of all the technologies used.\nSummary and final words I found the 2 courses to be very comprehensive and contain interesting materials. These knowledge from the 2 courses can supplement each other very well, and I recommend taking both of these courses if possible. But for further recommendation:\n If you do not have experience with Deep Learning beforehand, or you want to study the concept of MLOps without focusing too much on advanced details, the Udacity Nanodegree program is definitely the better choice. If you want to know the state-of-the-art techniques in AI - especially for Deep Learning models - and get used to the TensorFlow-related libraries and Google Cloud Platform, then the Coursera Specialization is the way to go.  A special thanks to my mentor at FPT Software AI Center, Dr. Khuong Nguyen, for recommending me these courses. Studying these courses helps me a lot to become a better Data Scientest and AI Engineer/Researcher.\nThere are some images in the post, some are mine, some are from the Internet, and it’s free to use as in the LICENSE below. But I always leave credit here to support authors, and so do you if you want to use content in my article.\nReferences  Image sources:  Figure 1: https://developers.google.com/machine-learning/crash-course/production-ml-systems Figure 2: https://www.tensorflow.org/tfx/guide Figure 3: https://cloud.google.com/blog/topics/developers-practitioners/use-vertex-pipelines-build-automl-classification-end-end-workflow   Reference courses:  Coursera Machine Learning Engineering for Production (MLOps) Specialization Udacity Nanodegree in Machine Learning DevOps Engineer    ","date":"2022-05-18T08:59:52+07:00","image":"https://dungminhdao.github.io/p/mlops-courses-review/background_hua3fa854e8703697468290c79ed714f75_61588_120x120_fill_box_smart1_3.png","permalink":"https://dungminhdao.github.io/p/mlops-courses-review/","title":"Machine Learning Operation (MLOps) Courses Review"},{"content":"Hi again. This is Dung Dao Minh, vice president of SoICT Innovation Club, and in this third post of series \u0026ldquo;Github 101\u0026rdquo;, I will talk about some kind of scenarios that can happen when you work on multiple branches in your work repositories, or work in collaboration with a team on a project.\nFirst words In many cases, you (and your collaborators) create multiple branches for different purpose: creating features, bug fixing, code versioning,\u0026hellip; Most of the issues happen when you try to combine the code between those branches: you may realize that you still commit to the main branch while fixing bugs/adding features, another developer may add a little documentation on your code (which is great), or your evil coworker might mess up with your code and make it full of bugs. In short, there may be some modification on the branch you are trying to merge into, that you need to resolve to (happily) combine the two different commits.\nI will create (with additional references from other sources) some different scenarios here that represent the problem you might face when working on different branches, and make it easy to introduce some new definition, as well as some good practices when working with Git and Github\nScenario #1: Working on new feature (no file conflict yet) Suppose that you are working on a project about real estate recommendation system, and you want to try using location information for your system. In the middle of your work, your boss want you to focus 100% of your time on improving system based on demographic information.\nStep 1: assume that you are on the develop branch. You should create a new branch location for developing the new feature:\n# Create and switch to new branch git checkout -b location # Commit as you go  git commit -m \u0026#34;add recommendation based on city\u0026#39; Step 2: however, you boss want you to focus on demographic features. You have not completed the location feature yet\n# Switch back to the develop branch git checkout develop # Create and switch to `demographic` branch git checkout -b demographic # Working on that branch and commit changes git commit -m \u0026#34;finalized demographic-based recommendation\u0026#34; Step 3: after you finish your work on demographic feature, you can merge it to the develop branch and push this to the remote origin/develop branch (assuming that both develop and origin/develop have no additional commit in the mean time)\n# Switch back to the develop branch git checkout develop # Merge the `demographic` branch into the `develop` branch git merge --no-ff demographic # Push to the remote repository git push origin develop Quick note on merge: fast-forward vs. no fast-forward You might see the --no-ff (no fast-forward) in the step 3 above. The new demographic code seems to only add new code, without any modification.\nA picture is worth a thousand words:\n Fast forward \n--no-ff will create a new commit (with new id, but the file content is the same), while by default, git merge will fast-forward - moving your branch pointer (in this case, at develop) to point at the incoming commit (from demographic).\nNote: when you merge with --no-ff, as a new commit is created, you might be asked to create message for that commit.\nIn many cases, you want to prevent fast-forward from happening, because you want to maintain a specific branch \u0026ldquo;shape\u0026rdquo;, and someone (your manager) can read the history of changes that you made from creating the demographic branch (instead of losing information when fast-forward)\nYou can change you command or do some setups to merge with or without feed-forward:\n# Execute for once: add the `--ff-only`, or `--no-ff` flag # Apply for both pull and merge (pull = fetch + merge) git pull --ff-only git pull --no-ff # Using git config to do it by default  # (git pull or git merge won\u0026#39;t need specific flag) git config --add merge.ff false git config --add merge.ff only Scenario #2: Same file names, different file contents on different branches (conflict) You might wonder what\u0026rsquo;s the purpose of the location branch created above. Now I will use it to demonstrate merge conflict.\nIn a bad mood, you forgot that you create that location branch for experimenting with location data, and you do some commit directly on the develop branch to work with that data. Let review some of the recent commits you made (notice the HEAD-\u0026gt;location (current branch) at commit f3b1b57 and the develop branch at commit 9a5187c)\ngit log --graph --decorate --oneline --all * 9a5187c (develop) add recommendation based on city in develop * 1fe34c7 Merge branch \u0026#39;demographic\u0026#39; into develop |\\ | * 0883fd7 (demographic) finalized demographic-based recommendation |/ | * f3b1b57 (HEAD -\u0026gt; location) add recommendation based on city |/ * b3a463a (origin/develop) Create develop branch For simple demonstration purpose, here are the 2 versions of location.txt on that 2 branches:\n# On `develop` branch location file in develop # On `location` branch location file Some ways you might consider to resolve the conflict When you realize the mistake, there are some cases here:\nCase 1: You recognize that there are part of the features you develop from both branches would be useful, and you want to combine them together.\nRun the command git merge develop will create the following message:\nAuto-merging location.txt CONFLICT (add/add): Merge conflict in location.txt Automatic merge failed; fix conflicts and then commit the result. This is inevitable, since the 2 files have different contents inside. Inside the location.txt file, you can see that the content has been modified. The upper part is the line of the current commit pointed by HEAD and the lower part is the\n\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD location file ======= location file in develop \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; develop Check git status for additional understanding:\nOn branch location You have unmerged paths. ... Unmerged paths: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to mark resolution) both added: location.txt To resolve the problem, simply modify the location.txt file as you wish (obviously, you don\u0026rsquo;t want those \u0026ldquo;\u0026laquo;\u0026lt;\u0026rdquo; or \u0026ldquo;===\u0026rdquo; characters anyway) and add it to the staging area, then create a new commit. Here I will modify the text into \u0026ldquo;location file after resolve conflict\u0026rdquo;:\ngit add location.txt git status # On branch location # All conflicts fixed but you are still merging. # ... git commit -m \u0026#34;resolve conflict in location feature\u0026#34; git log --graph --decorate --oneline --all # Now we see that the `location` branch has new commit * 1f79c56 (location) resolve conflict in location feature |\\  | * 9a5187c (HEAD -\u0026gt; develop) add recommendation based on city in develop | * 1fe34c7 Merge branch \u0026#39;demographic\u0026#39; into develop Case 2: You have done a far better work in the develop branch, and you don\u0026rsquo;t need the same code on location branch anymore. Or the other way around, you soon realize the mistake, and the location branch has more valuable code\nThe obvious solution is to use the code in develop instead of that code on location, or the other way around. You can use the approach in Case 1, observing that in some IDE, they support you with choosing the respective version you want. An example in VSCode (you can accept either change or both changes):\n Conflict VSCode \nA quicker way is to use additional flags, in favor of one of the branch (ours strategy refer to preference of the current branch, and theirs is the preference of the incoming branch):\ngit merge --strategy=ours develop git merge -X theirs develop Note: -s or --strategy completely ignore the other side, while -X or --strategy-option resolve any conflicts using the chosen side.\nAdditional note: merge vs rebase, and options for git pull Perhaps some animation is great here (acknowledgement to Nicola Paolucci\u0026rsquo;s post with the animations). Click on animated images to see how it works:  Merge   Rebase \nYou should use git rebase when your changes do not \u0026ldquo;deserve\u0026rdquo; a separate branch for its own. All the commands with merge above can also be done with rebase; note that it has a different behaviour as in the animations\nWhen working with remote directories, if you want to rebase instead of merge after fetching changes, you can add --rebase flag to the pull command:\n git pull = git fetch + git merge against tracking upstream branch git pull --rebase = git fetch + git rebase against tracking upstream branch  Final words The conflict in reality can be more complex, but in this episode, I have list the common cases you might face when you need to merge 2 branches together.\nThere are some images in the post, some are mine, some are from the Internet, and it’s free to use as in the LICENSE below. But I always leave credit here to support authors, and so do you if you want to use content in my article.\n A scenario from the Udacity\u0026rsquo;s Machine Learning DevOps Engineer helps me a lot in creating a bunch of scenarios above: https://www.udacity.com/course/machine-learning-dev-ops-engineer-nanodegree--nd0821 Answers on StackOverflow that help me with explanation (and images) in the process:  https://stackoverflow.com/questions/9069061/what-effect-does-the-no-ff-flag-have-for-git-merge https://stackoverflow.com/questions/18930527/difference-between-git-pull-and-git-pull-rebase https://stackoverflow.com/questions/173919/is-there-a-theirs-version-of-git-merge-s-ours https://stackoverflow.com/questions/2500296/can-i-make-fast-forwarding-be-off-by-default-in-git   Amazing images and explanations from Nicola Paolucci\u0026rsquo;s blog post: https://blog.developer.atlassian.com/pull-request-merge-strategies-the-great-debate/  ","date":"2022-05-04T21:55:37+07:00","image":"https://dungminhdao.github.io/p/getting-used-to-github-eps-3/merge_hu6ae8c8c5fad9c14566ba268e2c0186cc_78697_120x120_fill_box_smart1.gif","permalink":"https://dungminhdao.github.io/p/getting-used-to-github-eps-3/","title":"Getting Used to GitHub, Eps. 3"}]